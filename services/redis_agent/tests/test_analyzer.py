"""Tests for Redis Agent analyzer functionality.

Tests the LLM-powered analysis and periodic summaries.
"""

import builtins
import json
from types import SimpleNamespace
from typing import Any, AsyncGenerator

import pytest
import pytest_asyncio
from fakeredis import aioredis as fakeredis

from services.redis_agent.analyzer import (
    _format_metrics_brief,
    analyze_experiment_metrics,
    generate_summary,
)
from services.redis_agent.monitor import update_aggregations


@pytest.fixture
def mock_settings() -> SimpleNamespace:
    return SimpleNamespace(
        google_api_key="",
        redis_agent_model="test-model",
        summary_interval_seconds=1,
        orchestrator_channel="fullsend:to_orchestrator",
        metrics_channel="fullsend:metrics",
        threshold_check_interval_seconds=1,
        alert_cooldown_seconds=60,
    )


@pytest.fixture(autouse=True)
def patch_settings(monkeypatch, mock_settings):
    import services.redis_agent.alerts as alerts
    import services.redis_agent.analyzer as analyzer
    import services.redis_agent.monitor as monitor

    analyzer._settings = None
    monitor._settings = None
    alerts._settings = None

    monkeypatch.setattr(analyzer, "get_settings", lambda: mock_settings)
    monkeypatch.setattr(monitor, "get_settings", lambda: mock_settings)
    monkeypatch.setattr(alerts, "get_settings", lambda: mock_settings)
    yield
    analyzer._settings = None
    monitor._settings = None
    alerts._settings = None


@pytest_asyncio.fixture
async def redis() -> AsyncGenerator[Any, None]:
    """Create a fake Redis instance for testing."""
    fake_redis = fakeredis.FakeRedis()
    yield fake_redis
    await fake_redis.close()


class TestMetricsFormatting:
    """Tests for metrics formatting utilities."""

    def test_format_metrics_brief_empty(self):
        """Empty metrics returns placeholder."""
        assert _format_metrics_brief({}) == "no metrics yet"

    def test_format_metrics_brief_floats(self):
        """Float values formatted to 3 decimal places."""
        metrics = {"response_rate": 0.123456}
        result = _format_metrics_brief(metrics)
        assert "response_rate=0.123" in result

    def test_format_metrics_brief_integers(self):
        """Integer values included as-is."""
        metrics = {"count": 42}
        result = _format_metrics_brief(metrics)
        assert "count=42" in result

    def test_format_metrics_brief_skips_last_updated(self):
        """last_updated field is excluded from output."""
        metrics = {"count": 1, "last_updated": "2024-01-01T00:00:00"}
        result = _format_metrics_brief(metrics)
        assert "last_updated" not in result
        assert "count=1" in result

    def test_format_metrics_brief_limits_to_five(self):
        """Only first 5 metrics shown."""
        metrics = {f"metric_{i}": i for i in range(10)}
        result = _format_metrics_brief(metrics)
        # Count commas to verify at most 5 items
        assert result.count(",") <= 4


class TestGenerateSummary:
    """Tests for generate_summary function."""

    @pytest.mark.asyncio
    async def test_generate_summary_no_api_key(self, redis):
        """Returns mock summary when GOOGLE_API_KEY not set."""
        experiments = [{"id": "exp_1"}, {"id": "exp_2"}]
        result = await generate_summary(redis, experiments)

        assert "2 experiments" in result
        assert "Gemini not configured" in result

    @pytest.mark.asyncio
    async def test_generate_summary_missing_package(self, redis, mock_settings, monkeypatch):
        """Handles missing google-generativeai package gracefully."""
        experiments = [{"id": "exp_1"}]
        mock_settings.google_api_key = "test-key"

        original_import = builtins.__import__

        def fake_import(name, *args, **kwargs):
            if name == "google.generativeai":
                raise ImportError("No module named google.generativeai")
            return original_import(name, *args, **kwargs)

        monkeypatch.setattr(builtins, "__import__", fake_import)
        result = await generate_summary(redis, experiments)

        assert "1 experiments" in result
        assert "missing google-generativeai" in result


class TestAnalyzeExperimentMetrics:
    """Tests for analyze_experiment_metrics function."""

    @pytest.mark.asyncio
    async def test_analyze_experiment_not_found(self, redis):
        """Returns error message when experiment not found."""
        result = await analyze_experiment_metrics(redis, "nonexistent")
        assert "not found" in result

    @pytest.mark.asyncio
    async def test_analyze_experiment_no_api_key(self, redis):
        """Returns mock analysis when GOOGLE_API_KEY not set."""
        exp_id = "exp_test"

        # Create experiment
        await redis.hset(
            f"experiments:{exp_id}",
            mapping={
                "hypothesis": "Test hypothesis",
                "success_criteria": json.dumps(["rate > 0.1"]),
            },
        )
        result = await analyze_experiment_metrics(redis, exp_id)

        assert exp_id in result
        assert "Gemini not configured" in result

    @pytest.mark.asyncio
    async def test_analyze_includes_metrics(self, redis):
        """Analysis includes current metrics data."""
        exp_id = "exp_test"

        # Create experiment
        await redis.hset(
            f"experiments:{exp_id}",
            mapping={
                "hypothesis": "Test hypothesis",
                "success_criteria": json.dumps(["response_rate > 0.1"]),
                "failure_criteria": json.dumps(["response_rate < 0.02"]),
            },
        )

        # Add some metrics
        await update_aggregations(redis, exp_id, {"response_rate": 0.15})
        result = await analyze_experiment_metrics(redis, exp_id)

        # Should reference the experiment (even in mock mode)
        assert exp_id in result
